{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c99a4d7-6f47-419e-8f43-2085046f6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fc1172-01a9-48e8-80c6-2ff5fd05f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Equivariant_dim = 2\n",
    "Information_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd82c70-ace7-4d41-9523-eb8c1a7bf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e = torch.randn(int(1e6),Equivariant_dim)\n",
    "data_i = torch.rand(int(1e6),Information_dim)\n",
    "\n",
    "\n",
    "data = torch.concatenate([data_e,data_i],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac04b523-fdd9-4e94-9dc2-633f21d03f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_perturbed = data.clone()\n",
    "data_perturbed[:,0] = data_perturbed[:,0] + data_perturbed[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32d7ffe7-15c5-4174-ab03-fe56ad5cb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(x):\n",
    "    return (x[:,0] - x[:,2])**2 + x[:,1]**2 #+ x[:,2]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5a4be2a-a756-4b03-a58b-b252874d618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecorrelVAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_features,\n",
    "                 hidden_dims = 16,\n",
    "                 latent_dim = 16,\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask = nn.Parameter(torch.empty((1,latent_dim)))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.M_I = nn.Linear(in_features=latent_dim,\n",
    "                             out_features=latent_dim,\n",
    "                             bias=False) #No bias needed\n",
    "        \n",
    "        self.M_E = nn.Linear(in_features=latent_dim,\n",
    "                             out_features=latent_dim,\n",
    "                             bias=False) #No bias needed\n",
    "\n",
    "\n",
    "        self.Encoder = nn.Sequential(*[\n",
    "                nn.Linear(input_features,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,latent_dim)\n",
    "                ])\n",
    "\n",
    "        self.Decoder = nn.Sequential(*[\n",
    "                nn.Linear(latent_dim,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,input_features)\n",
    "                ])\n",
    "\n",
    "        \n",
    "        # This needs to be treated properly\n",
    "        self.mass_predictor = nn.Sequential(*[\n",
    "                nn.Linear(latent_dim,hidden_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dims,hidden_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dims,1)\n",
    "                ])        \n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "\n",
    "        x = self.Encoder(X)\n",
    "        #######################################################\n",
    "        eps_i = torch.randn_like(x)\n",
    "        f_i = x*torch.sigmoid((1-self.mask)).expand(x.shape[0],-1) + eps_i*torch.sigmoid(self.mask).expand(x.shape[0],-1)\n",
    "        f_i = self.M_I(f_i)\n",
    "        #######################################################\n",
    "\n",
    "        #######################################################\n",
    "        eps_ip = torch.randn_like(x)\n",
    "        f_e = x*torch.sigmoid(self.mask).expand(x.shape[0],-1) + eps_ip*torch.sigmoid((1-self.mask)).expand(x.shape[0],-1)\n",
    "        f_e = self.M_E(f_e)\n",
    "        ######################################################\n",
    "\n",
    "        mass = self.mass_predictor(f_e).squeeze()\n",
    "\n",
    "        reco_x = self.decoder(invariant = f_i,\n",
    "                            equivariant=f_e)\n",
    "        reco = self.Decoder(reco_x)\n",
    "        return f_i, f_e, mass, reco\n",
    "    \n",
    "    def decoder(self,invariant, equivariant):\n",
    "        return (invariant+equivariant)\n",
    "\n",
    "        \n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.mask, a=math.sqrt(5))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a3257-1738-4ace-8272-257bdbe8ffa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1472be9-df9c-470a-88a0-7e69d3c3d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4e2ed26-3fa3-41e1-94fc-922e5065cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorrel = DecorrelVAE(input_features=Equivariant_dim+Information_dim, hidden_dims=8, latent_dim=3)\n",
    "decorrel.to(device)\n",
    "optimizer_decorel = torch.optim.Adam(decorrel.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4de91925-8e76-4a82-b30f-4e5bff0a4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "904807b0-a653-4ef1-ad47-fd08887aef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f20c53b6344a9aa0c994e2ffcf8686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 complete\n",
      "=====================\n",
      "Loss Reconstruction 0.0012026249896734953\n",
      "Loss Mass Prediction 0.0005114519279431114\n",
      "EPOCH 10 complete\n",
      "=====================\n",
      "Loss Reconstruction 0.0008606830477893749\n",
      "Loss Mass Prediction 0.0004145740918343755\n",
      "EPOCH 20 complete\n",
      "=====================\n",
      "Loss Reconstruction 0.0006931200141228732\n",
      "Loss Mass Prediction 0.00037131143195631824\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m z \u001b[38;5;241m=\u001b[39m data[index[i\u001b[38;5;241m*\u001b[39mBATCH_SIZE:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mBATCH_SIZE],:]\n\u001b[1;32m     15\u001b[0m optimizer_decorel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m f_i, f_e, mass_pred, reco \u001b[38;5;241m=\u001b[39m \u001b[43mdecorrel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss_mass_pred \u001b[38;5;241m=\u001b[39m criterion_mse(psi(z),mass_pred)\n\u001b[1;32m     20\u001b[0m loss_reco \u001b[38;5;241m=\u001b[39m criterion_mse(z,reco)\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.12.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[78], line 59\u001b[0m, in \u001b[0;36mDecorrelVAE.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#######################################################\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#######################################################\u001b[39;00m\n\u001b[1;32m     58\u001b[0m eps_ip \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x)\n\u001b[0;32m---> 59\u001b[0m f_e \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask)\u001b[38;5;241m.\u001b[39mexpand(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m eps_ip\u001b[38;5;241m*\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m f_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM_E(f_e)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m######################################################\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = data.to(device)\n",
    "criterion_mse = nn.MSELoss()\n",
    "\n",
    "loss_reco_list = []\n",
    "loss_mass_list = []\n",
    "for epoch in tqdm(range(100)):\n",
    "    \n",
    "    loss_reco_ = 0\n",
    "    loss_mass_ = 0\n",
    "    \n",
    "    index = torch.randperm(data.shape[0])\n",
    "    for i in range(0,(data.shape[0]//BATCH_SIZE)+1):\n",
    "        z = data[index[i*BATCH_SIZE:(i+1)*BATCH_SIZE],:]\n",
    "        \n",
    "        optimizer_decorel.zero_grad()\n",
    "\n",
    "        f_i, f_e, mass_pred, reco = decorrel(z)\n",
    "\n",
    "        loss_mass_pred = criterion_mse(psi(z),mass_pred)\n",
    "        loss_reco = criterion_mse(z,reco)\n",
    "        \n",
    "        loss = loss_mass_pred + loss_reco\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_decorel.step()\n",
    "        \n",
    "        loss_reco_+=loss_reco.item()\n",
    "        loss_mass_+=loss_mass_pred.item()\n",
    "        \n",
    "    \n",
    "    loss_reco_ /= (data.shape[0]//BATCH_SIZE)+1\n",
    "    loss_mass_/= (data.shape[0]//BATCH_SIZE)+1\n",
    "    \n",
    "    loss_reco_list.append(loss_reco_)\n",
    "    loss_mass_list.append(loss_mass_)\n",
    "\n",
    "    if epoch%10 ==0 :\n",
    "        print(f\"EPOCH {epoch} complete\")\n",
    "        print(\"=====================\")\n",
    "        print(\"Loss Reconstruction\",loss_reco_)\n",
    "        print(\"Loss Mass Prediction\",loss_mass_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "073f3610-73aa-43fd-82fa-94d95d26b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i, f_e, mass_pred, reco = decorrel(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "992ff58e-8a44-46b7-add9-fdc5a4b3db04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.9706,  -8.9802, -25.5227],\n",
       "        [  3.5181,  -7.9578, -22.6149],\n",
       "        [  2.0994,  -4.7485, -13.4939],\n",
       "        ...,\n",
       "        [  0.5615,  -1.2718,  -3.6107],\n",
       "        [  2.6414,  -5.9739, -16.9765],\n",
       "        [ -2.3043,   5.2105,  14.8066]], device='cuda:0',\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc833bd3-3925-48c9-8243-927fb0c66a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9556, 0.3204, 0.9928]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(decorrel.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6511a915-3da3-46db-a30a-d4cc6051a561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7607, 1.5161, 0.4220], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorrel.Decoder(f_e+f_i)[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "086bf31a-0b29-4352-b7b0-9447f769b310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6765, 1.4567, 0.1328], device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66e488d3-eafc-4bdd-964a-13538a17a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_original = z.clone()\n",
    "z_original[:,0] = z[:,0] - z[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dbca1792-42be-4605-910d-5a3640757fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5436, 1.4567, 0.1328], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_original[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26a2a193-6f75-4a7b-8dca-095243d5ec7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'sh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mz_original\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msh\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sh'"
     ]
    }
   ],
   "source": [
    "z_original.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71c4a983-a99a-49ce-ac61-5563f30131b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-3.5184,  1.9926,  3.9571, -4.0639,  2.2235,  1.7557,  3.3118,  1.9644]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorrel.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f01364-22f7-42ee-b7bd-d4be5c646cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e = torch.randn(int(1e6),Equivariant_dim)\n",
    "data_i = torch.rand(int(1e6),Information_dim)\n",
    "\n",
    "\n",
    "data = torch.concatenate([data_e,data_i],-1)\n",
    "\n",
    "data_perturbed = data.clone()\n",
    "data_perturbed[:,0] = data_perturbed[:,0] + data_perturbed[:,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.12.0",
   "language": "python",
   "name": "tensorflow-2.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
